{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Nhd8KMxi-Bt6"},"source":["# 載入套件"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnC7wEOl-Bt7"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import librosa\n","import librosa.display\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import glob\n","import warnings\n","\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, recall_score, f1_score, classification_report, accuracy_score\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torch.nn.functional as F\n","\n","from torch.optim import Adam, SGD\n","from torchvision.transforms import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts,StepLR, ReduceLROnPlateau\n","from torchvision.io import read_image\n","from torchvision import transforms\n","from PIL import Image\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## voice preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# MFCC\n","def make_mfcc(df):\n","    for file in df['wave_path'].to_list():\n","        signal_tem, sample_rate = librosa.load(file, sr=44100)\n","        signal = signal_tem[:44100]\n","        n_fft = int(16/1000 * sample_rate)\n","        hop_length = int(8/1000 * sample_rate)\n","\n","        # extract 13 MFCCs\n","        MFCCs = librosa.feature.mfcc(y=signal, sr =sample_rate, n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n","        # print(MFCCs.shape)\n","        \n","        np.save(file.replace('.wav', f'_mfcc_13.npy'), MFCCs)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def medical_data_proccessing(df):\n","    # 將性別編碼0,1\n","    df['Sex'] = df['Sex'] - 1\n","\n","    # 將空值填0\n","    df['PPD'] = df['PPD'].fillna(0)\n","    df['Voice handicap index - 10'] = df['Voice handicap index - 10'].fillna(0)\n","\n","    # 正規化過大的數值\n","    df['Age'] = df['Age'] / 50\n","    df['Voice handicap index - 10'] = df['Voice handicap index - 10'] / 40\n","\n","    return df\n","\n","def normalization(data):\n","    _range = np.max(data) - np.min(data)\n","    return (data - np.min(data)) / _range\n"," \n","def standardization(data):\n","    mu = np.mean(data, axis=0)\n","    sigma = np.std(data, axis=0)\n","    return (data - mu) / sigma"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["warnings.filterwarnings(\"ignore\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train Dataset\n","class CustomImageDataset(Dataset):\n","    def __init__(self, source_df, transform=None, target_transform=None):\n","        medical_col = ['Sex', 'Age', 'Narrow pitch range',\n","                'Decreased volume', 'Fatigue', 'Dryness', 'Lumping', 'heartburn',\n","                'Choking', 'Eye dryness', 'PND', 'Smoking', 'PPD', 'Drinking',\n","                'frequency', 'Diurnal pattern', 'Onset of dysphonia ', 'Noise at work',\n","                'Occupational vocal demand', 'Diabetes', 'Hypertension', 'CAD',\n","                'Head and Neck Cancer', 'Head injury', 'CVA',\n","                'Voice handicap index - 10']\n","        \n","        self.dataframe = source_df\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","        try:\n","            self.medical = self.dataframe.drop(columns= ['ID', 'mfcc_path', 'Disease category', 'wave_path'])\n","        except:\n","            self.medical = self.dataframe.drop(columns= ['ID', 'mfcc_path', 'Disease category'])\n","        self.path = self.dataframe['mfcc_path']\n","        self.label = self.dataframe['Disease category']\n","    \n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.path.iloc[idx]\n","        \n","        np_araay = np.load(img_path)\n","        np_araay = standardization(np_araay)\n","\n","        medicals = self.medical.iloc[idx].values\n","        label = self.label.iloc[idx]\n","\n","        if self.transform:\n","            np_araay = self.transform(np_araay)\n","\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        \n","        return np_araay, medicals, label, img_path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Test dataset\n","class CustomImageDataset_test(Dataset):\n","    def __init__(self, source_df, transform=None, target_transform=None):\n","\n","        medical_col = ['Sex', 'Age', 'Narrow pitch range',\n","                'Decreased volume', 'Fatigue', 'Dryness', 'Lumping', 'heartburn',\n","                'Choking', 'Eye dryness', 'PND', 'Smoking', 'PPD', 'Drinking',\n","                'frequency', 'Diurnal pattern', 'Onset of dysphonia ', 'Noise at work',\n","                'Occupational vocal demand', 'Diabetes', 'Hypertension', 'CAD',\n","                'Head and Neck Cancer', 'Head injury', 'CVA',\n","                'Voice handicap index - 10']\n","        \n","        self.dataframe = source_df\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","        try:\n","            self.medical = self.dataframe.drop(columns= ['ID', 'mfcc_path', 'wave_path'])\n","        except:\n","            self.medical = self.dataframe.drop(columns= ['ID', 'mfcc_path'])\n","        self.path = self.dataframe['mfcc_path']\n","        self.id = self.dataframe['ID']\n","        # self.label = self.dataframe['Disease category']\n","        \n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.path.iloc[idx]\n","        \n","        np_araay = np.load(img_path)\n","        np_araay = standardization(np_araay)\n","\n","        medicals = self.medical.iloc[idx].values\n","        ids = self.id.iloc[idx]\n","        # label = self.label.iloc[idx]\n","\n","        if self.transform:\n","            np_araay = self.transform(np_araay)\n","\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        \n","        return np_araay, medicals, ids"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device('cuda:0')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Network(nn.Module):\n","    def __init__(self):\n","        super(Network, self).__init__()\n","        \n","        self.maxpool = 2\n","        \n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm2d(16)        \n","        self.pool1 = nn.MaxPool2d(self.maxpool, padding= 1)\n","\n","        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 10), stride=1, padding=1)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.pool2 = nn.MaxPool2d(self.maxpool, padding= 1)\n","        \n","        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 10), stride=1, padding=1)\n","        self.bn3 = nn.BatchNorm2d(64)\n","        self.pool3 = nn.MaxPool2d(self.maxpool, padding= 1)\n","\n","        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n","        self.bn4 = nn.BatchNorm2d(64)   \n","        self.pool4 = nn.MaxPool2d(self.maxpool, padding= 1)\n","\n","        self.conv5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n","        self.bn5 = nn.BatchNorm2d(64)\n","\n","        self.conv6 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n","        self.bn6 = nn.BatchNorm2d(64)\n","\n","        self.conv7 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n","        self.bn7 = nn.BatchNorm2d(128)\n","        \n","        self.conv_open = False\n","\n","        self.pools = 1\n","        self.ave_pool = nn.AdaptiveAvgPool2d(self.pools)\n","\n","        # MLP   \n","        self.linear1= nn.Linear(44, 1024)\n","        self.l1 = nn.BatchNorm1d(1024)\n","        self.drop2 = nn.Dropout(0.1)\n","        self.linear2= nn.Linear(1024, 256)\n","        self.l2 = nn.BatchNorm1d(256)\n","        self.linear3= nn.Linear(256, 128)\n","        \n","        # FC\n","        self.fc1_num = 128\n","        self.fc1 = nn.Linear(64 * self.pools * self.pools + 128, self.fc1_num)\n","        self.bnfc = nn.BatchNorm1d(self.fc1_num)\n","        self.fc2 = nn.Linear(self.fc1_num, 5)\n","        self.soft = nn.Softmax(dim=1)\n","        self.drop = nn.Dropout(0.3)\n","\n","\n","    def forward(self, input1, medical):\n","        # cnn\n","        output = F.celu(self.conv1(input1))\n","        output = self.bn1(output)\n","        output = self.pool1(output) \n","\n","        output = F.celu(self.conv2(output))     \n","        output = self.bn2(output)\n","        output = self.pool2(output)\n","\n","        output = F.celu(self.conv3(output)) \n","        output = self.bn3(output)\n","        output = self.pool3(output)   \n","\n","        output = self.ave_pool(output)\n","        output = output.view(-1, 64*self.pools*self.pools)\n","\n","        # med\n","        x = F.celu(self.linear1(medical))\n","        x = F.celu(self.linear2(x))\n","        x = F.celu(self.linear3(x))\n","        \n","        # concat\n","        con = torch.cat((output, x), 1)\n","        con = F.celu(self.fc1(con))\n","        con = self.bnfc(con)\n","        con = self.fc2(con)   \n","        con = self.soft(con)\n","\n","        return con"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## main"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train\n","df_train = pd.read_csv(r'..\\Training_Dataset\\training_datalist.csv')\n","df_train['wave_path'] = df_train['ID'].apply(lambda x: f'..\\\\Training_Dataset\\\\training_voice_data\\\\{x}.wav')\n","make_mfcc(df_train)\n","df_train['mfcc_path'] = df_train['ID'].apply(lambda x: f'..\\\\Training_Dataset\\\\training_voice_data\\\\{x}_mfcc_13.npy')\n","\n","# public\n","source_df_pub = pd.read_csv(r'..\\Public Testing Dataset\\test_datalist_public.csv')\n","source_df_pub['wave_path'] = source_df_pub['ID'].apply(lambda x: f'..\\\\Public Testing Dataset\\\\test_data_public\\\\{x}.wav')\n","make_mfcc(source_df_pub)\n","source_df_pub['mfcc_path'] = source_df_pub['ID'].apply(lambda x: f'..\\\\Public Testing Dataset\\\\test_data_public\\\\{x}_mfcc_13.npy')\n","\n","# private\n","source_df_pri = pd.read_csv(r'..\\Private Testing Dataset\\test_datalist_private.csv')\n","source_df_pri['wave_path'] = source_df_pri['ID'].apply(lambda x: f'..\\\\Private Testing Dataset\\\\test_data_private\\\\{x}.wav')\n","make_mfcc(source_df_pri)\n","source_df_pri['mfcc_path'] = source_df_pri['ID'].apply(lambda x: f'..\\\\Private Testing Dataset\\\\test_data_private\\\\{x}_mfcc_13.npy')\n","\n","\n","# make dataloder\n","source_df = medical_data_proccessing(df_train)\n","source_df = pd.get_dummies(source_df, columns=['Smoking', 'frequency', 'Onset of dysphonia ', 'Noise at work', 'Diurnal pattern', 'Occupational vocal demand'])\n","source_df['Disease category'] = source_df['Disease category'] - 1\n","\n","skf = StratifiedKFold(n_splits=4, shuffle=True)\n","fold1 = list(skf.split(source_df, source_df['Disease category']))[0]\n","\n","training_df = source_df.loc[fold1[0]]\n","test_df = source_df.loc[fold1[1]]\n","\n","cat_num_list = training_df['Disease category'].value_counts().sort_index().to_list()\n","\n","trans_comp = transforms.Compose([transforms.ToTensor()])\n","train_dataset = CustomImageDataset(training_df, transform=trans_comp)\n","test_dataset = CustomImageDataset(test_df, transform=trans_comp)\n","\n","train_dl = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n","test_dl = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# model\n","model = Network().to(device)\n","\n","weight = torch.tensor([1/cat_num_list[0], 1/cat_num_list[1], 1/cat_num_list[2], 1/cat_num_list[3], 1/cat_num_list[4]]).to(device)\n","criterion = nn.CrossEntropyLoss(weight=weight)\n","\n","optimizer = SGD(model.parameters(), lr=0.01, weight_decay= 0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(15):\n","    # read file\n","    if i > 0:\n","        df_train = pd.read_csv(r'..\\Training_Dataset\\training_datalist.csv')\n","        df_train['mfcc_path'] = df_train['ID'].apply(lambda x: f'..\\\\Training_Dataset\\\\training_voice_data\\\\{x}_mfcc_13.npy')\n","\n","        df_public = pd.read_csv(r'.\\pesudo_pub_mfcc_13.csv')\n","        df_public['mfcc_path'] = df_public['ID'].apply(lambda x: f'..\\\\Public Testing Dataset\\\\test_data_public\\\\{x}_mfcc_13.npy')\n","        df_public['Sex'] = df_public['Sex'] + 1\n","\n","        df_private = pd.read_csv(r'.\\pesudo_pri_mfcc_13.csv')\n","        df_private['mfcc_path'] = df_private['ID'].apply(lambda x: f'..\\\\Private Testing Dataset\\\\test_data_private\\\\{x}_mfcc_13.npy')\n","        df_private['Sex'] = df_private['Sex'] + 1\n","\n","        source_df = pd.concat([df_train, df_public, df_private], axis=0, ignore_index=True)\n","    else:\n","        df_train = pd.read_csv(r'..\\Training_Dataset\\training_datalist.csv')\n","        df_train['mfcc_path'] = df_train['ID'].apply(lambda x: f'..\\\\Training_Dataset\\\\training_voice_data\\\\{x}_mfcc_13.npy')\n","        source_df = df_train\n","\n","    # make dataloder\n","    source_df = medical_data_proccessing(source_df)\n","    source_df = pd.get_dummies(source_df, columns=['Smoking', 'frequency', 'Onset of dysphonia ', 'Noise at work', 'Diurnal pattern', 'Occupational vocal demand'])\n","    source_df['Disease category'] = source_df['Disease category'] - 1\n","\n","    skf = StratifiedKFold(n_splits=4, shuffle=True)\n","    fold1 = list(skf.split(source_df, source_df['Disease category']))[0]\n","\n","    training_df = source_df.loc[fold1[0]]\n","    test_df = source_df.loc[fold1[1]]\n","\n","    cat_num_list = training_df['Disease category'].value_counts().sort_index().to_list()\n","\n","    trans_comp = transforms.Compose([transforms.ToTensor()])\n","    train_dataset = CustomImageDataset(training_df, transform=trans_comp)\n","    test_dataset = CustomImageDataset(test_df, transform=trans_comp)\n","\n","    train_dl = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n","    test_dl = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","    # model\n","    model = Network().to(device)\n","\n","    weight = torch.tensor([1/cat_num_list[0], 1/cat_num_list[1], 1/cat_num_list[2], 1/cat_num_list[3], 1/cat_num_list[4]]).to(device)\n","    criterion = nn.CrossEntropyLoss(weight=weight)\n","\n","    optimizer = SGD(model.parameters(), lr=0.01, weight_decay= 0.0001)\n","\n","    # train\n","    train_acc_list = [0]\n","    test_acc_list = [0]\n","    before_acc = 0.\n","    epoch = 150\n","    for epoch in range(epoch):\n","        pred_list = []\n","        label_list = []\n","        \n","        size = len(train_dl.dataset)    \n","        losses = 0.\n","        accuracies = 0.\n","        total = 0\n","        \n","        for batch, (np_araay, medicals, labels, img_path) in enumerate(train_dl):\n","            model.train()\n","            \n","            inputs, medicals, labels = np_araay.float().to(device), medicals.float().to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            preds = model(inputs, medicals)\n","            \n","            loss = criterion(preds, labels)\n","            losses = losses + loss.item()\n","\n","            # backpropagation        \n","            loss.backward()\n","            optimizer.step()\n","\n","            pred = list(preds.cpu().argmax(1))\n","            label = list(labels.cpu())\n","            \n","            pred_list += pred\n","            label_list += label\n","\n","        y_pred = [a.item() for a in pred_list]\n","        y_true = [b.item() for b in label_list]\n","\n","        results_recall = recall_score(y_true, y_pred, average=None)\n","        train_acc_list.append(results_recall.mean())\n","\n","        # pesudo label\n","        pred_list = []\n","        label_list = []\n","        model.eval()\n","        with torch.no_grad():\n","            for np_araay, medicals, labels, img_path in test_dl:\n","                inputs, medicals, labels = np_araay.float().to(device), medicals.float().to(device), labels.to(device)\n","\n","                preds = model(inputs, medicals)\n","                \n","                pred = list(preds.cpu().argmax(1))\n","                label = list(labels.cpu())\n","                \n","                pred_list += pred\n","                label_list += label\n","\n","        y_true_test = [a.item() for a in pred_list]\n","        y_pred_test = [b.item() for b in label_list]\n","\n","        results_recall_test = recall_score(y_true_test, y_pred_test, average=None)\n","        test_mean = results_recall_test.mean()\n","        test_acc_list.append(test_mean)\n","\n","        bad_group = (results_recall_test[3] + results_recall_test[4])/2\n","\n","        if test_mean > before_acc :\n","            before_acc = test_mean\n","            torch.save(model.state_dict(), \"{}.pth\".format(\"mfcc_13\"))\n","\n","    # load model\n","    model.load_state_dict(torch.load(\"{}.pth\".format(\"mfcc_13\")))\n","\n","    # public\n","    source_df_pub = pd.read_csv(r'..\\Public Testing Dataset\\test_datalist_public.csv')\n","    source_df_pub['mfcc_path'] = source_df_pub['ID'].apply(lambda x: f'..\\\\Public Testing Dataset\\\\test_data_public\\\\{x}_mfcc_13.npy')\n","\n","    source_df_pub_pro = medical_data_proccessing(source_df_pub)\n","    source_df_pub_pro = pd.get_dummies(source_df_pub_pro, columns=['Smoking', 'frequency', 'Onset of dysphonia ', 'Noise at work', 'Diurnal pattern', 'Occupational vocal demand'])\n","\n","    trans_comp = transforms.Compose([transforms.ToTensor()])\n","    pub_dataset = CustomImageDataset_test(source_df_pub_pro, transform=trans_comp)\n","    pub_dl = DataLoader(pub_dataset, batch_size=32, shuffle=False)\n","\n","    pub_pred_list = []\n","    model.eval()\n","    with torch.no_grad():\n","        for np_araay, medicals, img_path in pub_dl:\n","            inputs, medicals= np_araay.float().to(device), medicals.float().to(device)\n","            preds = model(inputs, medicals)\n","            pred = list(preds.cpu().argmax(1))\n","            pub_pred_list += pred\n","\n","    y_pub = [x.item() for x in pub_pred_list]\n","    source_df_pub['Disease category'] = [cat + 1 for cat in y_pub]\n","    source_df_pub.to_csv('pesudo_pub_mfcc_13.csv', index=False)\n","\n","    # private\n","    source_df_pri = pd.read_csv(r'..\\Private Testing Dataset\\test_datalist_private.csv')\n","    source_df_pri['mfcc_path'] = source_df_pri['ID'].apply(lambda x: f'..\\\\Private Testing Dataset\\\\test_data_private\\\\{x}_mfcc_13.npy')\n","\n","    source_df_pri_pro = medical_data_proccessing(source_df_pri)\n","    source_df_pri_pro = pd.get_dummies(source_df_pri_pro, columns=['Smoking', 'frequency', 'Onset of dysphonia ', 'Noise at work', 'Diurnal pattern', 'Occupational vocal demand'])\n","\n","    pri_dataset = CustomImageDataset_test(source_df_pri_pro, transform=trans_comp)\n","    pri_dl = DataLoader(pri_dataset, batch_size=32, shuffle=False)\n","\n","    pri_pred_list = []\n","    model.eval()\n","    with torch.no_grad():\n","        for np_araay, medicals, img_path in pri_dl:\n","            inputs, medicals= np_araay.float().to(device), medicals.float().to(device)\n","            preds = model(inputs, medicals)\n","            pred = list(preds.cpu().argmax(1))\n","            pri_pred_list += pred\n","    \n","    y_pri = [x.item() for x in pri_pred_list]\n","    source_df_pri['Disease category'] = [cat + 1 for cat in y_pri]\n","    source_df_pri.to_csv('pesudo_pri_mfcc_13.csv', index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## make submission"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.load_state_dict(torch.load(\"{}.pth\".format(\"mfcc_13\")))\n","\n","# public\n","source_df_pub = pd.read_csv(r'..\\Public Testing Dataset\\test_datalist_public.csv')\n","source_df_pub['wave_path'] = source_df_pub['ID'].apply(lambda x: f'..\\\\Public Testing Dataset\\\\test_data_public\\\\{x}.wav')\n","# make_mfcc(source_df_pub)\n","source_df_pub['mfcc_path'] = source_df_pub['ID'].apply(lambda x: f'..\\\\Public Testing Dataset\\\\test_data_public\\\\{x}_mfcc_13.npy')\n","\n","source_df_pub_pro = medical_data_proccessing(source_df_pub)\n","source_df_pub_pro = pd.get_dummies(source_df_pub_pro, columns=['Smoking', 'frequency', 'Onset of dysphonia ', 'Noise at work', 'Diurnal pattern', 'Occupational vocal demand'])\n","\n","trans_comp = transforms.Compose([transforms.ToTensor()])\n","pub_dataset = CustomImageDataset_test(source_df_pub_pro, transform=trans_comp)\n","pub_dl = DataLoader(pub_dataset, batch_size=32, shuffle=False)\n","\n","pub_pred_list = []\n","model.eval()\n","with torch.no_grad():\n","    for np_araay, medicals, img_path in pub_dl:\n","        inputs, medicals= np_araay.float().to(device), medicals.float().to(device)\n","        preds = model(inputs, medicals)\n","        pred = list(preds.cpu().argmax(1))\n","        pub_pred_list += pred\n","\n","y_pub = [x.item() for x in pub_pred_list]\n","\n","# private\n","source_df_pri = pd.read_csv(r'..\\Private Testing Dataset\\test_datalist_private.csv')\n","source_df_pri['wave_path'] = source_df_pri['ID'].apply(lambda x: f'..\\\\Private Testing Dataset\\\\test_data_private\\\\{x}.wav')\n","# make_mfcc(source_df_pri)\n","source_df_pri['mfcc_path'] = source_df_pri['ID'].apply(lambda x: f'..\\\\Private Testing Dataset\\\\test_data_private\\\\{x}_mfcc_13.npy')\n","\n","source_df_pri_pro = medical_data_proccessing(source_df_pri)\n","source_df_pri_pro = pd.get_dummies(source_df_pri_pro, columns=['Smoking', 'frequency', 'Onset of dysphonia ', 'Noise at work', 'Diurnal pattern', 'Occupational vocal demand'])\n","\n","pri_dataset = CustomImageDataset_test(source_df_pri_pro, transform=trans_comp)\n","pri_dl = DataLoader(pri_dataset, batch_size=32, shuffle=False)\n","\n","pri_pred_list = []\n","model.eval()\n","with torch.no_grad():\n","    for np_araay, medicals, img_path in pri_dl:\n","        inputs, medicals= np_araay.float().to(device), medicals.float().to(device)\n","        preds = model(inputs, medicals)\n","        pred = list(preds.cpu().argmax(1))\n","        pri_pred_list += pred\n","\n","y_pri = [x.item() for x in pri_pred_list]\n","\n","# combine submission\n","tem_pub_pri = pd.read_csv(r'..\\Private Testing Dataset\\submission_template_public+private.csv',header=None)\n","y_pub_pri = y_pub + y_pri\n","tem_pub_pri[1] = [x + 1 for x in y_pub_pri]\n","tem_pub_pri.to_csv('pub_pri_mfcc_13.csv', header=False, index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"modelenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f97432c16914304dbd818b138841742b9483a5a148ca981647dc7438178b3282"}}},"nbformat":4,"nbformat_minor":0}
